{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this toturial, we want to integrate Keras models with [Tensorflow Estimators](https://www.tensorflow.org/extend/estimators). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This tutorial essentially follow the same approach described in [this tutorial](https://www.tensorflow.org/extend/estimators), however, instead of using Tensorflow layers, we want to use Keras layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our model consists of two fully connected layers with the relu activation function followed by a linear layer without non-linearity. So, lets implement it with Kera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# # This returns a tensor\n",
    "# inputs = Input(shape=(784,))\n",
    "\n",
    "# # a layer instance is callable on a tensor, and returns a tensor\n",
    "# x = Dense(64, activation='relu')(inputs)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# predictions = Dense(10, activation='softmax')(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is downloaded to /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmpqzf0g8aj\n",
      "Test data is downloaded to /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmpapbmua_m\n",
      "Prediction data is downloaded to /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmp8gysvgjq\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_model_dir': None, '_num_ps_replicas': 0, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': None, '_master': '', '_save_checkpoints_secs': 600, '_task_id': 0, '_task_type': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11726e7b8>, '_num_worker_replicas': 0, '_environment': 'local', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      "}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmptfjinenw\n",
      "test\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmptfjinenw/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 89.9793\n",
      "INFO:tensorflow:global_step/sec: 1052.81\n",
      "INFO:tensorflow:step = 101, loss = 11.3562 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1128.13\n",
      "INFO:tensorflow:step = 201, loss = 6.04521 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1140.5\n",
      "INFO:tensorflow:step = 301, loss = 5.35003 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1142.88\n",
      "INFO:tensorflow:step = 401, loss = 8.84587 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1117.05\n",
      "INFO:tensorflow:step = 501, loss = 5.66859 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1092.02\n",
      "INFO:tensorflow:step = 601, loss = 6.94219 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1156.99\n",
      "INFO:tensorflow:step = 701, loss = 6.48142 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1081.06\n",
      "INFO:tensorflow:step = 801, loss = 4.95528 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1115.14\n",
      "INFO:tensorflow:step = 901, loss = 7.22586 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1134.02\n",
      "INFO:tensorflow:step = 1001, loss = 6.25778 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 994.807\n",
      "INFO:tensorflow:step = 1101, loss = 7.32206 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 886.039\n",
      "INFO:tensorflow:step = 1201, loss = 6.45891 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.533\n",
      "INFO:tensorflow:step = 1301, loss = 7.36475 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.161\n",
      "INFO:tensorflow:step = 1401, loss = 7.26051 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 875.427\n",
      "INFO:tensorflow:step = 1501, loss = 4.6248 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 896.707\n",
      "INFO:tensorflow:step = 1601, loss = 3.48031 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 872.289\n",
      "INFO:tensorflow:step = 1701, loss = 4.68438 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 918.146\n",
      "INFO:tensorflow:step = 1801, loss = 6.83692 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1148.32\n",
      "INFO:tensorflow:step = 1901, loss = 4.84579 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1153.73\n",
      "INFO:tensorflow:step = 2001, loss = 6.30666 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1136.21\n",
      "INFO:tensorflow:step = 2101, loss = 6.4086 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1133.5\n",
      "INFO:tensorflow:step = 2201, loss = 6.06001 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1117.98\n",
      "INFO:tensorflow:step = 2301, loss = 4.57497 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1134.2\n",
      "INFO:tensorflow:step = 2401, loss = 8.27762 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1089.28\n",
      "INFO:tensorflow:step = 2501, loss = 6.84454 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 898.586\n",
      "INFO:tensorflow:step = 2601, loss = 3.81084 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.666\n",
      "INFO:tensorflow:step = 2701, loss = 9.17543 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1083.08\n",
      "INFO:tensorflow:step = 2801, loss = 7.60237 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 897.256\n",
      "INFO:tensorflow:step = 2901, loss = 5.65826 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 878.889\n",
      "INFO:tensorflow:step = 3001, loss = 5.47217 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.335\n",
      "INFO:tensorflow:step = 3101, loss = 4.34673 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 894.718\n",
      "INFO:tensorflow:step = 3201, loss = 4.7519 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.565\n",
      "INFO:tensorflow:step = 3301, loss = 6.41656 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.792\n",
      "INFO:tensorflow:step = 3401, loss = 5.162 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 829.194\n",
      "INFO:tensorflow:step = 3501, loss = 4.30352 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.925\n",
      "INFO:tensorflow:step = 3601, loss = 3.47544 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 932.992\n",
      "INFO:tensorflow:step = 3701, loss = 3.38516 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 920.852\n",
      "INFO:tensorflow:step = 3801, loss = 5.5659 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 885.175\n",
      "INFO:tensorflow:step = 3901, loss = 6.56448 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 848.45\n",
      "INFO:tensorflow:step = 4001, loss = 5.24008 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.847\n",
      "INFO:tensorflow:step = 4101, loss = 4.13244 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.618\n",
      "INFO:tensorflow:step = 4201, loss = 4.27719 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 946.744\n",
      "INFO:tensorflow:step = 4301, loss = 4.71044 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 929.463\n",
      "INFO:tensorflow:step = 4401, loss = 4.80579 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1082.76\n",
      "INFO:tensorflow:step = 4501, loss = 5.11521 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1133.62\n",
      "INFO:tensorflow:step = 4601, loss = 4.04718 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1139.24\n",
      "INFO:tensorflow:step = 4701, loss = 3.24515 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1132.19\n",
      "INFO:tensorflow:step = 4801, loss = 4.67792 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1060.73\n",
      "INFO:tensorflow:step = 4901, loss = 6.74601 (0.094 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmptfjinenw/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.51608.\n",
      "WARNING:tensorflow:From <ipython-input-12-19ba5fa32e8d>:160: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-12-19ba5fa32e8d>:160: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majid/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:248: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-04-05-23:55:02\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmptfjinenw/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-04-05-23:55:02\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.53387, rmse = 2.35242\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Loss: 5.53387\n",
      "Root Mean Squared Error: 2.35242\n",
      "test\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/_g/9zy1zpy55c59kbl62wkkj6hm0000gn/T/tmptfjinenw/model.ckpt-5000\n",
      "{'ages': array([  4.6201067 ,  10.41481686,   7.14297915,  10.65043831,\n",
      "        10.94178391,   9.2508297 ,  11.34892464], dtype=float32)}\n",
      "Prediction 1: 4.62011\n",
      "Prediction 2: 10.4148\n",
      "Prediction 3: 7.14298\n",
      "Prediction 4: 10.6504\n",
      "Prediction 5: 10.9418\n",
      "Prediction 6: 9.25083\n",
      "Prediction 7: 11.3489\n"
     ]
    }
   ],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "from tensorflow.contrib.learn.python.learn.estimators.estimator import SKCompat as SKCompat\n",
    "from tensorflow.contrib.learn import Estimator as Estimator\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Learning rate for the model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def maybe_download(train_data, test_data, predict_data):\n",
    "  \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "  if train_data:\n",
    "    train_file_name = train_data\n",
    "  else:\n",
    "    train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_train.csv\",\n",
    "        train_file.name)\n",
    "    train_file_name = train_file.name\n",
    "    train_file.close()\n",
    "    print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "  if test_data:\n",
    "    test_file_name = test_data\n",
    "  else:\n",
    "    test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_test.csv\", test_file.name)\n",
    "    test_file_name = test_file.name\n",
    "    test_file.close()\n",
    "    print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "  if predict_data:\n",
    "    predict_file_name = predict_data\n",
    "  else:\n",
    "    predict_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_predict.csv\",\n",
    "        predict_file.name)\n",
    "    predict_file_name = predict_file.name\n",
    "    predict_file.close()\n",
    "    print(\"Prediction data is downloaded to %s\" % predict_file_name)\n",
    "\n",
    "  return train_file_name, test_file_name, predict_file_name\n",
    "\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "  \"\"\"Model function for Estimator.\"\"\"\n",
    "  print(\"test\")\n",
    "  # Connect the first hidden layer to input layer\n",
    "  # (features) with relu activation\n",
    "  first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "  # Connect the second hidden layer to first hidden layer with relu\n",
    "  second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "  # Connect the output layer to second hidden layer (no activation fn)\n",
    "  output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(targets, tf.float32), predictions)\n",
    "  }\n",
    "\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=params[\"learning_rate\"],\n",
    "      optimizer=\"SGD\")\n",
    "\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "parser.add_argument(\n",
    "  \"--train_data\", type=str, default=\"\", help=\"Path to the training data.\")\n",
    "parser.add_argument(\n",
    "  \"--test_data\", type=str, default=\"\", help=\"Path to the test data.\")\n",
    "parser.add_argument(\n",
    "  \"--predict_data\",\n",
    "  type=str,\n",
    "  default=\"\",\n",
    "  help=\"Path to the prediction data.\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "\n",
    "# def main(unused_argv):\n",
    "  # Load datasets\n",
    "abalone_train, abalone_test, abalone_predict = maybe_download(\n",
    "    FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)\n",
    "\n",
    "# Training examples\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=abalone_train, target_dtype=np.int, features_dtype=np.float32)\n",
    "\n",
    "# Test examples\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=abalone_test, target_dtype=np.int, features_dtype=np.float32)\n",
    "\n",
    "# Set of 7 examples for which to predict abalone ages\n",
    "prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=abalone_predict, target_dtype=np.int, features_dtype=np.float32)\n",
    "\n",
    "# Set model params\n",
    "model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "# Instantiate Estimator\n",
    "est = Estimator(model_fn=model_fn, params=model_params)\n",
    "nn = SKCompat(est)\n",
    "\n",
    "# Fit\n",
    "nn.fit(x=training_set.data, y=training_set.target, steps=5000)\n",
    "\n",
    "# Score accuracy\n",
    "ev = est.evaluate(x=test_set.data, y=test_set.target, steps=1)\n",
    "print(\"Loss: %s\" % ev[\"loss\"])\n",
    "print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])\n",
    "\n",
    "# Print out predictions\n",
    "predictions = nn.predict(x=prediction_set.data)\n",
    "print(predictions)\n",
    "for i, p in enumerate(predictions['ages']):\n",
    "  print(\"Prediction %s: %s\" % (i + 1, p))\n",
    "\n",
    "\n",
    "# tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.57161617,  10.36000156,   7.23409271,  10.63977051,\n",
       "        11.09867287,   9.45869637,  11.08108139], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['ages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: 4.57162\n",
      "Prediction 2: 10.36\n",
      "Prediction 3: 7.23409\n",
      "Prediction 4: 10.6398\n",
      "Prediction 5: 11.0987\n",
      "Prediction 6: 9.4587\n",
      "Prediction 7: 11.0811\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(predictions['ages']):\n",
    "  print(\"Prediction %s: %s\" % (i + 1, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
